{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X8JSbwyOmyuQ",
        "qcqFbzIcAHfu",
        "sHvUqkVkyf4I",
        "kUHKz3FKvH8g",
        "9vN-2CGmy72w"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c5a480745af14c0e8f8a305e79d2d836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de3c8393afc34297aa139e5f1a38b41e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_edebd1179c69441d9852588a947e1391",
              "IPY_MODEL_4a7a80855eb24bb4b1d84fa978035e1a"
            ]
          }
        },
        "de3c8393afc34297aa139e5f1a38b41e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edebd1179c69441d9852588a947e1391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_596efe1f2911407997286ebfab76de3c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4495d1df39c64c938e9183b25344b37e"
          }
        },
        "4a7a80855eb24bb4b1d84fa978035e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d9f932b0045644da9e4a2bc575204cce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [04:58&lt;00:00, 820kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abb7a8a88dc948e69c572eb413c35705"
          }
        },
        "596efe1f2911407997286ebfab76de3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4495d1df39c64c938e9183b25344b37e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9f932b0045644da9e4a2bc575204cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abb7a8a88dc948e69c572eb413c35705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GirishShanmugam/transfer-learning/blob/master/Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8JSbwyOmyuQ",
        "colab_type": "text"
      },
      "source": [
        "# AlexNet Model architecture playground "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60ZTBNcqnQyU",
        "colab_type": "code",
        "outputId": "7f239d3f-8c5a-4c2e-9cfe-f5abef5c357b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559,
          "referenced_widgets": [
            "c5a480745af14c0e8f8a305e79d2d836",
            "de3c8393afc34297aa139e5f1a38b41e",
            "edebd1179c69441d9852588a947e1391",
            "4a7a80855eb24bb4b1d84fa978035e1a",
            "596efe1f2911407997286ebfab76de3c",
            "4495d1df39c64c938e9183b25344b37e",
            "d9f932b0045644da9e4a2bc575204cce",
            "abb7a8a88dc948e69c572eb413c35705"
          ]
        }
      },
      "source": [
        "# get AlexNet architecture since AlexNet has only 5 convolutional layers\n",
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /root/.cache/torch/hub/v0.6.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5a480745af14c0e8f8a305e79d2d836",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_Y_9wVqwJmJ",
        "colab_type": "code",
        "outputId": "881f017a-ab10-4bbe-a9d5-35c0612fa8b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model_false = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=False)\n",
        "## weights for bias in 1st Conv layer without the pretrained weights\n",
        "model_false.state_dict()['features.0.bias'][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0033,  0.0278, -0.0510,  0.0133, -0.0128, -0.0222, -0.0315, -0.0266,\n",
              "        -0.0035, -0.0368])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdlpR4qCoMbd",
        "colab_type": "code",
        "outputId": "b532fadb-6507-4345-e734-e0cc78a8c413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model.state_dict().keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'features.6.weight', 'features.6.bias', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0GFZBJBqXR_",
        "colab_type": "code",
        "outputId": "0d804358-728a-4df4-cc39-6d5e7007d7d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.state_dict()['features.0.weight'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 11, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUemtU9iqc9a",
        "colab_type": "code",
        "outputId": "2f1ed931-4b57-4546-95c4-4ce6b1903ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.state_dict()['features.0.bias'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrwECyNxyJrw",
        "colab_type": "code",
        "outputId": "41a83ce2-52e9-4809-b05b-a42610544e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model.state_dict()['features.0.weight'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 11, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRYQzthy5hsM",
        "colab_type": "text"
      },
      "source": [
        "### Helper function to retain layers from AlexNet model and reinitialise other layers to random weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIfKovWI6Imc",
        "colab_type": "code",
        "outputId": "03d31b35-996b-4f21-cec0-caf1a48dbf6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# weights for bias in 1st Conv layer before modifying\n",
        "model.state_dict()['features.0.bias'][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9705, -2.8070, -0.0371, -0.0795, -0.1159,  0.0252, -0.0752, -1.4181,\n",
              "         1.6454, -0.0990])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11dOz4Q15FPv",
        "colab_type": "code",
        "outputId": "f9f7a603-df9b-411c-cd58-318b47b7c31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# weights for bias in 4th Conv layer before modifying\n",
        "model.state_dict()['features.8.bias'][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0629,  0.1260,  0.2991,  0.1123,  0.2853,  0.1280,  0.1828, -0.0310,\n",
              "         0.5452,  0.1565])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qEgxeOrzQWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retain_layers(model, num_layers_retain):\n",
        "  total_cnn_layers = 5\n",
        "  layer_names = ['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'features.6.weight', 'features.6.bias', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias']\n",
        "  for i in range(num_layers_retain, total_cnn_layers):\n",
        "    sd = model.state_dict()\n",
        "    feature = layer_names[i*2]\n",
        "    bias = layer_names[(i*2)+1]\n",
        "    sd[feature].normal_()\n",
        "    sd[bias].normal_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q_jJcBk2Z-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retain first three layers\n",
        "retain_layers(model, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7fKUJQ26T0w",
        "colab_type": "code",
        "outputId": "6241b17a-6d89-498b-d097-471f63424d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# weights for bias in 1st Conv layer after modifying\n",
        "model.state_dict()['features.0.bias'][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9705, -2.8070, -0.0371, -0.0795, -0.1159,  0.0252, -0.0752, -1.4181,\n",
              "         1.6454, -0.0990])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc55IX1G3DHq",
        "colab_type": "code",
        "outputId": "996cd23a-77c1-4b61-fa0d-59c7b0b54c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# weights for bias in 4th Conv layer after modifying\n",
        "model.state_dict()['features.8.bias'][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4857,  1.9247, -0.4161,  0.6972, -0.4460,  1.0776, -0.4933,  0.6414,\n",
              "         0.6040,  1.1095])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcqFbzIcAHfu",
        "colab_type": "text"
      },
      "source": [
        "# Load cats Vs Dogs dataset\n",
        "https://www.pluralsight.com/guides/image-classification-with-pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gvLeyXXKGWQ",
        "colab_type": "code",
        "outputId": "0ce4f425-f988-4eea-be27-4b29c55f12bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1HbB79OKpi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/kaggle.zip\" -d \"/content/KaggleImages\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap1IqjYc_Lrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.image as img\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaJ-bN6WaB1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = pd.read_csv('/content/KaggleImages/train/train.csv')\n",
        "\n",
        "train_path = '/content/KaggleImages/train/train/'\n",
        "test_path = '/content/KaggleImages/train/test/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tKtcZyR1xky",
        "colab_type": "code",
        "outputId": "48b1854c-30c6-4d18-898b-2fc016472f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "labels.columns = ['id', 'classes']\n",
        "labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cat.8010.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cat.10013.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cat.11131.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cat.10323.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cat.9163.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  classes\n",
              "0   cat.8010.jpg        0\n",
              "1  cat.10013.jpg        0\n",
              "2  cat.11131.jpg        0\n",
              "3  cat.10323.jpg        0\n",
              "4   cat.9163.jpg        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLUn2cZbadLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CatsDogsDataset(Dataset):\n",
        "    def __init__(self, data, path , transform = None):\n",
        "        super().__init__()\n",
        "        self.data = data.values\n",
        "        self.path = path\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        img_name,label = self.data[index]\n",
        "        img_path = os.path.join(self.path, img_name)\n",
        "        image = img.imread(img_path)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHvUqkVkyf4I",
        "colab_type": "text"
      },
      "source": [
        "# Helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0FahpndyjGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Function to train and evaluate the performance of the model\n",
        "def run_and_evaluate_model(device, model, train_loader, valid_loader, num_epochs, learning_rate):\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # keeping-track-of-losses\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        # keep-track-of-training-and-validation-loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        # training-the-model\n",
        "        model.train()\n",
        "        for data, target in train_loader:\n",
        "            # move-tensors-to-GPU\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # clear-the-gradients-of-all-optimized-variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n",
        "            output = model(data)\n",
        "            # calculate-the-batch-loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\n",
        "            loss.backward()\n",
        "            # perform-a-ingle-optimization-step (parameter-update)\n",
        "            optimizer.step()\n",
        "            # update-training-loss\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "\n",
        "        # validate-the-model\n",
        "        model.eval()\n",
        "        for data, target in valid_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # update-average-validation-loss\n",
        "            valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "        # calculate-average-losses\n",
        "        train_loss = train_loss / len(train_loader.sampler)\n",
        "        valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "        train_losses.append(train_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "        # print-training/validation-statistics\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, train_loss, valid_loss))\n",
        "\n",
        "    # test-the-model\n",
        "    model.eval()  # it-disables-dropout\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print('Test Accuracy of the model: {} %'.format(100 * correct / total))\n",
        "\n",
        "\n",
        "# Helper function to retain layers from AlexNet model and reinitialise other layers to random weights\n",
        "def retain_layers(model, num_layers_retain):\n",
        "  total_cnn_layers = 5\n",
        "  layer_names = ['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'features.6.weight', 'features.6.bias', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias']\n",
        "  for i in range(num_layers_retain, total_cnn_layers):\n",
        "    sd = model.state_dict()\n",
        "    feature = layer_names[i*2]\n",
        "    bias = layer_names[(i*2)+1]\n",
        "    sd[feature].normal_()\n",
        "    sd[bias].normal_()\n",
        "\n",
        "# freeze or fine tune weights of n layers\n",
        "# https://discuss.pytorch.org/t/how-the-pytorch-freeze-network-in-some-layers-only-the-rest-of-the-training/7088\n",
        "def process_weights(model, start, end, grad_bool):\n",
        "  i=0\n",
        "  for param in model.parameters():\n",
        "    if((i>=start*2) & (i<end*2)):\n",
        "      param.requires_grad=grad_bool\n",
        "    i+=1\n",
        "\n",
        "# Helper function to copy n layers from source model to destination model\n",
        "# https://discuss.pytorch.org/t/copy-weights-only-from-a-networks-parameters/5841\n",
        "def copy_layers(num_layers, source, dest):\n",
        "  layer_names = ['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'features.6.weight', 'features.6.bias', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias']\n",
        "  for i in range(0, num_layers):\n",
        "    source_sd = source.state_dict()\n",
        "    dest_sd = dest.state_dict()\n",
        "    feature = layer_names[i*2]\n",
        "    bias = layer_names[(i*2)+1]\n",
        "    dest.state_dict()[feature].data.copy_(source.state_dict()[feature].data)\n",
        "    dest.state_dict()[bias].data.copy_(source.state_dict()[bias].data)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gty6yxqtvH8Y"
      },
      "source": [
        "# Experiment 1: Train on similar pairs\n",
        "\n",
        "- Dataset A: Use pretrained weights from AlexNet model trained on 1000 classes which also has cat family in it.\n",
        "- Dataset B - cats vs dogs Kaggle dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kUHKz3FKvH8g"
      },
      "source": [
        "## baseB \n",
        "AlexNet architecture trained on Cats Vs Dogs dataset(start with random weights)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "38000207-1091-4f77-ec1c-c70a0054ebcd",
        "id": "j6kwhp15vH8j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "baseB = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r9UTwrANvH8q",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "baseB.classifier[6] = nn.Linear(4096,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qib_g8TVgi6r",
        "colab_type": "code",
        "outputId": "ffe26513-2b84-4332-df01-675b9b4b28f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "%%time\n",
        "import os\n",
        "\n",
        "# fine tune weights of all layers\n",
        "for param in baseB.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "run_and_evaluate_model(device, baseB, train_loader, valid_loader, 10, 0.0001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.637744 \tValidation Loss: 0.565206\n",
            "Epoch: 2 \tTraining Loss: 0.551213 \tValidation Loss: 0.486575\n",
            "Epoch: 3 \tTraining Loss: 0.467945 \tValidation Loss: 0.403803\n",
            "Epoch: 4 \tTraining Loss: 0.399915 \tValidation Loss: 0.368508\n",
            "Epoch: 5 \tTraining Loss: 0.363385 \tValidation Loss: 0.394250\n",
            "Epoch: 6 \tTraining Loss: 0.320510 \tValidation Loss: 0.320756\n",
            "Epoch: 7 \tTraining Loss: 0.284907 \tValidation Loss: 0.296111\n",
            "Epoch: 8 \tTraining Loss: 0.250198 \tValidation Loss: 0.284210\n",
            "Epoch: 9 \tTraining Loss: 0.227215 \tValidation Loss: 0.301802\n",
            "Epoch: 10 \tTraining Loss: 0.207007 \tValidation Loss: 0.290472\n",
            "Test Accuracy of the model: 88.66 %\n",
            "CPU times: user 19min 5s, sys: 4min 22s, total: 23min 28s\n",
            "Wall time: 23min 29s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzWLAEPmG4wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(baseB.state_dict(), '/content/baseB.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBmyRk1GdTSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(baseB.state_dict(), '/content/drive/My Drive/baseB.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vN-2CGmy72w",
        "colab_type": "text"
      },
      "source": [
        "## A selffer network BnB: \n",
        "Copy first n layers from baseB (freeze it). Initialize random weights to rest of the 5-n layers and train on dataset B.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZzLkD4aKWQq",
        "colab_type": "code",
        "outputId": "ee587c55-b6e5-406b-9494-92244bc6e54f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# retain n layers and reinitialise weights of others layers randomnly\n",
        "# layers 1 to 5\n",
        "for layer in range(1,6):\n",
        "  bnb = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=False)\n",
        "  bnb.classifier[6] = nn.Linear(4096,2)\n",
        "  # load pretrained model baseB\n",
        "  baseB = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=False)\n",
        "  baseB.classifier[6] = nn.Linear(4096,2)\n",
        "  baseB.load_state_dict(torch.load('/content/baseB.pt'))\n",
        "  print('Starting for BnB model retaining {} layers'.format(layer))\n",
        "  copy_layers(layer, baseB, bnb)\n",
        "  # freeze weights of n layers \n",
        "  process_weights(bnb, 0, layer, False)\n",
        "  # fine tune weights of rest of the layers\n",
        "  process_weights(bnb, layer+1, 4, True)\n",
        "  # run and evaluate the model\n",
        "  run_and_evaluate_model(device, bnb, train_loader, valid_loader, 10, 0.0001)\n",
        "  filename_to_save = '/content/b{}b.pt'.format(layer)\n",
        "  torch.save(bnb.state_dict(), filename_to_save)\n",
        "  print('Done for BnB model retaining {} layers'.format(layer))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting for BnB model retaining 1 layers\n",
            "Epoch: 1 \tTraining Loss: 0.589532 \tValidation Loss: 0.495153\n",
            "Epoch: 2 \tTraining Loss: 0.447200 \tValidation Loss: 0.405460\n",
            "Epoch: 3 \tTraining Loss: 0.368963 \tValidation Loss: 0.332988\n",
            "Epoch: 4 \tTraining Loss: 0.318728 \tValidation Loss: 0.319364\n",
            "Epoch: 5 \tTraining Loss: 0.275829 \tValidation Loss: 0.337379\n",
            "Epoch: 6 \tTraining Loss: 0.242921 \tValidation Loss: 0.315663\n",
            "Epoch: 7 \tTraining Loss: 0.224671 \tValidation Loss: 0.282036\n",
            "Epoch: 8 \tTraining Loss: 0.193219 \tValidation Loss: 0.239311\n",
            "Epoch: 9 \tTraining Loss: 0.178112 \tValidation Loss: 0.258173\n",
            "Epoch: 10 \tTraining Loss: 0.162300 \tValidation Loss: 0.270426\n",
            "Test Accuracy of the model: 88.26 %\n",
            "Done for BnB model retaining 1 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting for BnB model retaining 2 layers\n",
            "Epoch: 1 \tTraining Loss: 0.412052 \tValidation Loss: 0.333380\n",
            "Epoch: 2 \tTraining Loss: 0.278988 \tValidation Loss: 0.296388\n",
            "Epoch: 3 \tTraining Loss: 0.237101 \tValidation Loss: 0.288449\n",
            "Epoch: 4 \tTraining Loss: 0.213525 \tValidation Loss: 0.262319\n",
            "Epoch: 5 \tTraining Loss: 0.192672 \tValidation Loss: 0.255807\n",
            "Epoch: 6 \tTraining Loss: 0.170237 \tValidation Loss: 0.263823\n",
            "Epoch: 7 \tTraining Loss: 0.152085 \tValidation Loss: 0.275732\n",
            "Epoch: 8 \tTraining Loss: 0.138548 \tValidation Loss: 0.266952\n",
            "Epoch: 9 \tTraining Loss: 0.116431 \tValidation Loss: 0.302033\n",
            "Epoch: 10 \tTraining Loss: 0.100325 \tValidation Loss: 0.275027\n",
            "Test Accuracy of the model: 89.86 %\n",
            "Done for BnB model retaining 2 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting for BnB model retaining 3 layers\n",
            "Epoch: 1 \tTraining Loss: 0.301221 \tValidation Loss: 0.313323\n",
            "Epoch: 2 \tTraining Loss: 0.191233 \tValidation Loss: 0.275082\n",
            "Epoch: 3 \tTraining Loss: 0.171066 \tValidation Loss: 0.267987\n",
            "Epoch: 4 \tTraining Loss: 0.158872 \tValidation Loss: 0.299178\n",
            "Epoch: 5 \tTraining Loss: 0.140954 \tValidation Loss: 0.290376\n",
            "Epoch: 6 \tTraining Loss: 0.127916 \tValidation Loss: 0.267371\n",
            "Epoch: 7 \tTraining Loss: 0.120978 \tValidation Loss: 0.289526\n",
            "Epoch: 8 \tTraining Loss: 0.107958 \tValidation Loss: 0.285314\n",
            "Epoch: 9 \tTraining Loss: 0.092864 \tValidation Loss: 0.335742\n",
            "Epoch: 10 \tTraining Loss: 0.083186 \tValidation Loss: 0.341399\n",
            "Test Accuracy of the model: 90.02 %\n",
            "Done for BnB model retaining 3 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting for BnB model retaining 4 layers\n",
            "Epoch: 1 \tTraining Loss: 0.237714 \tValidation Loss: 0.273810\n",
            "Epoch: 2 \tTraining Loss: 0.172235 \tValidation Loss: 0.282654\n",
            "Epoch: 3 \tTraining Loss: 0.152712 \tValidation Loss: 0.278243\n",
            "Epoch: 4 \tTraining Loss: 0.153663 \tValidation Loss: 0.270739\n",
            "Epoch: 5 \tTraining Loss: 0.142451 \tValidation Loss: 0.272843\n",
            "Epoch: 6 \tTraining Loss: 0.138961 \tValidation Loss: 0.285328\n",
            "Epoch: 7 \tTraining Loss: 0.128646 \tValidation Loss: 0.289930\n",
            "Epoch: 8 \tTraining Loss: 0.119393 \tValidation Loss: 0.293517\n",
            "Epoch: 9 \tTraining Loss: 0.111263 \tValidation Loss: 0.297982\n",
            "Epoch: 10 \tTraining Loss: 0.103281 \tValidation Loss: 0.369145\n",
            "Test Accuracy of the model: 88.08 %\n",
            "Done for BnB model retaining 4 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting for BnB model retaining 5 layers\n",
            "Epoch: 1 \tTraining Loss: 0.195434 \tValidation Loss: 0.270427\n",
            "Epoch: 2 \tTraining Loss: 0.160437 \tValidation Loss: 0.289919\n",
            "Epoch: 3 \tTraining Loss: 0.158014 \tValidation Loss: 0.267478\n",
            "Epoch: 4 \tTraining Loss: 0.156608 \tValidation Loss: 0.271834\n",
            "Epoch: 5 \tTraining Loss: 0.149011 \tValidation Loss: 0.260921\n",
            "Epoch: 6 \tTraining Loss: 0.150541 \tValidation Loss: 0.278384\n",
            "Epoch: 7 \tTraining Loss: 0.145072 \tValidation Loss: 0.283326\n",
            "Epoch: 8 \tTraining Loss: 0.143151 \tValidation Loss: 0.275561\n",
            "Epoch: 9 \tTraining Loss: 0.144783 \tValidation Loss: 0.277534\n",
            "Epoch: 10 \tTraining Loss: 0.140061 \tValidation Loss: 0.289059\n",
            "Test Accuracy of the model: 88.94 %\n",
            "Done for BnB model retaining 5 layers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM56m8g9Nndi",
        "colab_type": "text"
      },
      "source": [
        "## A selffer network BnB+ \n",
        "Copy first n layers from baseB. Initialize random weights to rest of the 5-n layers and train on dataset B. Fine tune all layers. (similar to BnB but the first n layers also learn - fine tuned)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BpUDRN6N8p7",
        "colab_type": "code",
        "outputId": "926625f8-9691-4b66-9770-8d5a69f68e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# retain n layers and reinitialise weights of others layers randomnly\n",
        "# layers 1 to 5\n",
        "import torch.nn as nn\n",
        "for layer in range(1,6):\n",
        "  bnb_plus = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=False)\n",
        "  bnb_plus.classifier[6] = nn.Linear(4096,2)\n",
        "  # load pretrained model baseB\n",
        "  baseB = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=False)\n",
        "  baseB.classifier[6] = nn.Linear(4096,2)\n",
        "  baseB.load_state_dict(torch.load('/content/drive/My Drive/baseB.pt'))\n",
        "  print('Starting for BnB+ model retaining {} layers'.format(layer))\n",
        "  copy_layers(layer, baseB, bnb_plus)\n",
        "  # fine tune weights n layers \n",
        "  process_weights(bnb_plus, 0, 7, True)\n",
        "  # run and evaluate the model\n",
        "  run_and_evaluate_model(device, bnb_plus, train_loader, valid_loader, 10, 0.0001)\n",
        "  filename_to_save = '/content/b{}b_plus.pt'.format(layer)\n",
        "  torch.save(bnb_plus.state_dict(), filename_to_save)\n",
        "  print('Done for BnB+ model retaining {} layers'.format(layer))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting for BnB+ model retaining 1 layers\n",
            "Epoch: 1 \tTraining Loss: 0.589587 \tValidation Loss: 0.512487\n",
            "Epoch: 2 \tTraining Loss: 0.448498 \tValidation Loss: 0.463368\n",
            "Epoch: 3 \tTraining Loss: 0.370550 \tValidation Loss: 0.335956\n",
            "Epoch: 4 \tTraining Loss: 0.317403 \tValidation Loss: 0.350193\n",
            "Epoch: 5 \tTraining Loss: 0.277443 \tValidation Loss: 0.322709\n",
            "Epoch: 6 \tTraining Loss: 0.247494 \tValidation Loss: 0.265882\n",
            "Epoch: 7 \tTraining Loss: 0.221237 \tValidation Loss: 0.374590\n",
            "Epoch: 8 \tTraining Loss: 0.201461 \tValidation Loss: 0.276919\n",
            "Epoch: 9 \tTraining Loss: 0.185629 \tValidation Loss: 0.273070\n",
            "Epoch: 10 \tTraining Loss: 0.161459 \tValidation Loss: 0.255688\n",
            "Test Accuracy of the model: 90.38 %\n",
            "Done for BnB+ model retaining 1 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting for BnB+ model retaining 2 layers\n",
            "Epoch: 1 \tTraining Loss: 0.454023 \tValidation Loss: 0.355175\n",
            "Epoch: 2 \tTraining Loss: 0.320311 \tValidation Loss: 0.356163\n",
            "Epoch: 3 \tTraining Loss: 0.271721 \tValidation Loss: 0.267823\n",
            "Epoch: 4 \tTraining Loss: 0.240043 \tValidation Loss: 0.272047\n",
            "Epoch: 5 \tTraining Loss: 0.213833 \tValidation Loss: 0.229677\n",
            "Epoch: 6 \tTraining Loss: 0.199220 \tValidation Loss: 0.303319\n",
            "Epoch: 7 \tTraining Loss: 0.179762 \tValidation Loss: 0.259940\n",
            "Epoch: 8 \tTraining Loss: 0.167909 \tValidation Loss: 0.251242\n",
            "Epoch: 9 \tTraining Loss: 0.151535 \tValidation Loss: 0.274372\n",
            "Epoch: 10 \tTraining Loss: 0.133218 \tValidation Loss: 0.243327\n",
            "Test Accuracy of the model: 90.54 %\n",
            "Done for BnB+ model retaining 2 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting for BnB+ model retaining 3 layers\n",
            "Epoch: 1 \tTraining Loss: 0.336355 \tValidation Loss: 0.261463\n",
            "Epoch: 2 \tTraining Loss: 0.236556 \tValidation Loss: 0.225064\n",
            "Epoch: 3 \tTraining Loss: 0.213572 \tValidation Loss: 0.221664\n",
            "Epoch: 4 \tTraining Loss: 0.180006 \tValidation Loss: 0.206216\n",
            "Epoch: 5 \tTraining Loss: 0.168452 \tValidation Loss: 0.225036\n",
            "Epoch: 6 \tTraining Loss: 0.149342 \tValidation Loss: 0.227628\n",
            "Epoch: 7 \tTraining Loss: 0.140446 \tValidation Loss: 0.228019\n",
            "Epoch: 8 \tTraining Loss: 0.120190 \tValidation Loss: 0.231299\n",
            "Epoch: 9 \tTraining Loss: 0.116431 \tValidation Loss: 0.244923\n",
            "Epoch: 10 \tTraining Loss: 0.102813 \tValidation Loss: 0.235891\n",
            "Test Accuracy of the model: 90.46 %\n",
            "Done for BnB+ model retaining 3 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting for BnB+ model retaining 4 layers\n",
            "Epoch: 1 \tTraining Loss: 0.280518 \tValidation Loss: 0.303413\n",
            "Epoch: 2 \tTraining Loss: 0.210153 \tValidation Loss: 0.222308\n",
            "Epoch: 3 \tTraining Loss: 0.189364 \tValidation Loss: 0.230899\n",
            "Epoch: 4 \tTraining Loss: 0.173242 \tValidation Loss: 0.213975\n",
            "Epoch: 5 \tTraining Loss: 0.154907 \tValidation Loss: 0.216714\n",
            "Epoch: 6 \tTraining Loss: 0.137838 \tValidation Loss: 0.204756\n",
            "Epoch: 7 \tTraining Loss: 0.123023 \tValidation Loss: 0.217752\n",
            "Epoch: 8 \tTraining Loss: 0.112168 \tValidation Loss: 0.238508\n",
            "Epoch: 9 \tTraining Loss: 0.099096 \tValidation Loss: 0.222311\n",
            "Epoch: 10 \tTraining Loss: 0.089305 \tValidation Loss: 0.216878\n",
            "Test Accuracy of the model: 91.68 %\n",
            "Done for BnB+ model retaining 4 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting for BnB+ model retaining 5 layers\n",
            "Epoch: 1 \tTraining Loss: 0.251807 \tValidation Loss: 0.197138\n",
            "Epoch: 2 \tTraining Loss: 0.195547 \tValidation Loss: 0.229731\n",
            "Epoch: 3 \tTraining Loss: 0.174059 \tValidation Loss: 0.241781\n",
            "Epoch: 4 \tTraining Loss: 0.161160 \tValidation Loss: 0.232894\n",
            "Epoch: 5 \tTraining Loss: 0.142501 \tValidation Loss: 0.205531\n",
            "Epoch: 6 \tTraining Loss: 0.124503 \tValidation Loss: 0.210309\n",
            "Epoch: 7 \tTraining Loss: 0.111700 \tValidation Loss: 0.198145\n",
            "Epoch: 8 \tTraining Loss: 0.106472 \tValidation Loss: 0.211181\n",
            "Epoch: 9 \tTraining Loss: 0.088697 \tValidation Loss: 0.220313\n",
            "Epoch: 10 \tTraining Loss: 0.086696 \tValidation Loss: 0.239889\n",
            "Test Accuracy of the model: 92.12 %\n",
            "Done for BnB+ model retaining 5 layers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pst-Rc5pw0m6",
        "colab_type": "text"
      },
      "source": [
        "## A transfer network AnB\n",
        "copy first n layers from baseA (freeze it). Initialize random weights to rest of the 8-n layers and train on dataset B. Similarly for BnA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8ItDXmNcIj_",
        "colab_type": "code",
        "outputId": "c3fdf55e-373e-4151-e1d9-a3e09eaa6e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# retain n layers and reinitialise weights of others layers randomnly\n",
        "# layers 1 to 5\n",
        "for layer in range(1,6):\n",
        "  print('Starting for AnB model retaining {} layers'.format(layer))\n",
        "  baseA = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
        "  baseA.classifier[6] = nn.Linear(4096,2)\n",
        "  anb = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=False)\n",
        "  anb.classifier[6] = nn.Linear(4096,2)\n",
        "  copy_layers(layer, baseA, anb)\n",
        "  # freeze weights of n layers \n",
        "  process_weights(anb, 0, layer, False)\n",
        "  # fine tune weights of rest of the layers\n",
        "  process_weights(anb, layer+1, 4, True)\n",
        "  # run and evaluate the model\n",
        "  run_and_evaluate_model(device, anb, train_loader, valid_loader, 10, 0.0001)\n",
        "  filename_to_save = '/content/a{}b.pt'.format(layer)\n",
        "  torch.save(anb.state_dict(), filename_to_save)\n",
        "  print('Done for AnB model retaining {} layers'.format(layer))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting for AnB model retaining 1 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.532784 \tValidation Loss: 0.404830\n",
            "Epoch: 2 \tTraining Loss: 0.352845 \tValidation Loss: 0.299854\n",
            "Epoch: 3 \tTraining Loss: 0.268402 \tValidation Loss: 0.255555\n",
            "Epoch: 4 \tTraining Loss: 0.219287 \tValidation Loss: 0.233037\n",
            "Epoch: 5 \tTraining Loss: 0.194542 \tValidation Loss: 0.303903\n",
            "Epoch: 6 \tTraining Loss: 0.161313 \tValidation Loss: 0.217261\n",
            "Epoch: 7 \tTraining Loss: 0.140624 \tValidation Loss: 0.222362\n",
            "Epoch: 8 \tTraining Loss: 0.128312 \tValidation Loss: 0.256599\n",
            "Epoch: 9 \tTraining Loss: 0.113848 \tValidation Loss: 0.193603\n",
            "Epoch: 10 \tTraining Loss: 0.093255 \tValidation Loss: 0.252533\n",
            "Test Accuracy of the model: 91.2 %\n",
            "Done for AnB model retaining 1 layers\n",
            "Starting for AnB model retaining 2 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.376147 \tValidation Loss: 0.247009\n",
            "Epoch: 2 \tTraining Loss: 0.204089 \tValidation Loss: 0.189057\n",
            "Epoch: 3 \tTraining Loss: 0.161612 \tValidation Loss: 0.170093\n",
            "Epoch: 4 \tTraining Loss: 0.132191 \tValidation Loss: 0.177748\n",
            "Epoch: 5 \tTraining Loss: 0.111832 \tValidation Loss: 0.155051\n",
            "Epoch: 6 \tTraining Loss: 0.089541 \tValidation Loss: 0.179828\n",
            "Epoch: 7 \tTraining Loss: 0.075702 \tValidation Loss: 0.144337\n",
            "Epoch: 8 \tTraining Loss: 0.072322 \tValidation Loss: 0.172647\n",
            "Epoch: 9 \tTraining Loss: 0.058901 \tValidation Loss: 0.140863\n",
            "Epoch: 10 \tTraining Loss: 0.051009 \tValidation Loss: 0.173269\n",
            "Test Accuracy of the model: 94.44 %\n",
            "Done for AnB model retaining 2 layers\n",
            "Starting for AnB model retaining 3 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.292756 \tValidation Loss: 0.156340\n",
            "Epoch: 2 \tTraining Loss: 0.145768 \tValidation Loss: 0.141686\n",
            "Epoch: 3 \tTraining Loss: 0.107848 \tValidation Loss: 0.154926\n",
            "Epoch: 4 \tTraining Loss: 0.084308 \tValidation Loss: 0.125095\n",
            "Epoch: 5 \tTraining Loss: 0.066580 \tValidation Loss: 0.119691\n",
            "Epoch: 6 \tTraining Loss: 0.057137 \tValidation Loss: 0.154950\n",
            "Epoch: 7 \tTraining Loss: 0.045381 \tValidation Loss: 0.145288\n",
            "Epoch: 8 \tTraining Loss: 0.033792 \tValidation Loss: 0.138760\n",
            "Epoch: 9 \tTraining Loss: 0.027301 \tValidation Loss: 0.207695\n",
            "Epoch: 10 \tTraining Loss: 0.028496 \tValidation Loss: 0.134712\n",
            "Test Accuracy of the model: 95.84 %\n",
            "Done for AnB model retaining 3 layers\n",
            "Starting for AnB model retaining 4 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.250403 \tValidation Loss: 0.150158\n",
            "Epoch: 2 \tTraining Loss: 0.130926 \tValidation Loss: 0.125552\n",
            "Epoch: 3 \tTraining Loss: 0.099047 \tValidation Loss: 0.112330\n",
            "Epoch: 4 \tTraining Loss: 0.073130 \tValidation Loss: 0.111434\n",
            "Epoch: 5 \tTraining Loss: 0.055201 \tValidation Loss: 0.122666\n",
            "Epoch: 6 \tTraining Loss: 0.046068 \tValidation Loss: 0.125104\n",
            "Epoch: 7 \tTraining Loss: 0.037848 \tValidation Loss: 0.138084\n",
            "Epoch: 8 \tTraining Loss: 0.028065 \tValidation Loss: 0.181047\n",
            "Epoch: 9 \tTraining Loss: 0.028711 \tValidation Loss: 0.153542\n",
            "Epoch: 10 \tTraining Loss: 0.022308 \tValidation Loss: 0.153554\n",
            "Test Accuracy of the model: 95.42 %\n",
            "Done for AnB model retaining 4 layers\n",
            "Starting for AnB model retaining 5 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.195049 \tValidation Loss: 0.140850\n",
            "Epoch: 2 \tTraining Loss: 0.145275 \tValidation Loss: 0.123046\n",
            "Epoch: 3 \tTraining Loss: 0.128264 \tValidation Loss: 0.124296\n",
            "Epoch: 4 \tTraining Loss: 0.116773 \tValidation Loss: 0.116355\n",
            "Epoch: 5 \tTraining Loss: 0.108522 \tValidation Loss: 0.119290\n",
            "Epoch: 6 \tTraining Loss: 0.105906 \tValidation Loss: 0.113246\n",
            "Epoch: 7 \tTraining Loss: 0.094582 \tValidation Loss: 0.113889\n",
            "Epoch: 8 \tTraining Loss: 0.088052 \tValidation Loss: 0.108864\n",
            "Epoch: 9 \tTraining Loss: 0.080239 \tValidation Loss: 0.120565\n",
            "Epoch: 10 \tTraining Loss: 0.076454 \tValidation Loss: 0.115906\n",
            "Test Accuracy of the model: 95.44 %\n",
            "Done for AnB model retaining 5 layers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DXgb8dkWfEkM"
      },
      "source": [
        "## A transfer network AnB+\n",
        "copy first n layers from baseA. Initialize random weights to rest of the 8-n layers and train on dataset B. All layers learn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a1a22b69-bb98-4dec-deb8-b2260b48ec12",
        "id": "MUW2MYbdfEkN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# retain n layers and reinitialise weights of others layers randomnly\n",
        "# layers 1 to 5\n",
        "for layer in range(1,6):\n",
        "  print('Starting for AnB+ model retaining {} layers'.format(layer))\n",
        "  baseA = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
        "  baseA.classifier[6] = nn.Linear(4096,2)\n",
        "  anb_plus = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=False)\n",
        "  anb_plus.classifier[6] = nn.Linear(4096,2)\n",
        "  copy_layers(layer, baseA, anb_plus)\n",
        "  # fine tune weights of all the layers\n",
        "  process_weights(anb_plus, 0, 7, True)\n",
        "  # run and evaluate the model\n",
        "  run_and_evaluate_model(device, anb_plus, train_loader, valid_loader, 10, 0.0001)\n",
        "  filename_to_save = '/content/a{}b_plus.pt'.format(layer)\n",
        "  torch.save(anb_plus.state_dict(), filename_to_save)\n",
        "  print('Done for AnB+ model retaining {} layers'.format(layer))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting for AnB+ model retaining 1 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.540102 \tValidation Loss: 0.435978\n",
            "Epoch: 2 \tTraining Loss: 0.376330 \tValidation Loss: 0.289890\n",
            "Epoch: 3 \tTraining Loss: 0.288823 \tValidation Loss: 0.267015\n",
            "Epoch: 4 \tTraining Loss: 0.234938 \tValidation Loss: 0.254160\n",
            "Epoch: 5 \tTraining Loss: 0.197645 \tValidation Loss: 0.222235\n",
            "Epoch: 6 \tTraining Loss: 0.171155 \tValidation Loss: 0.282656\n",
            "Epoch: 7 \tTraining Loss: 0.145379 \tValidation Loss: 0.195860\n",
            "Epoch: 8 \tTraining Loss: 0.132656 \tValidation Loss: 0.183249\n",
            "Epoch: 9 \tTraining Loss: 0.114516 \tValidation Loss: 0.190224\n",
            "Epoch: 10 \tTraining Loss: 0.098854 \tValidation Loss: 0.202404\n",
            "Test Accuracy of the model: 92.76 %\n",
            "Done for AnB+ model retaining 1 layers\n",
            "Starting for AnB+ model retaining 2 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.422621 \tValidation Loss: 0.236330\n",
            "Epoch: 2 \tTraining Loss: 0.225053 \tValidation Loss: 0.168417\n",
            "Epoch: 3 \tTraining Loss: 0.160698 \tValidation Loss: 0.208771\n",
            "Epoch: 4 \tTraining Loss: 0.133372 \tValidation Loss: 0.139041\n",
            "Epoch: 5 \tTraining Loss: 0.104261 \tValidation Loss: 0.139929\n",
            "Epoch: 6 \tTraining Loss: 0.084357 \tValidation Loss: 0.192645\n",
            "Epoch: 7 \tTraining Loss: 0.072295 \tValidation Loss: 0.144538\n",
            "Epoch: 8 \tTraining Loss: 0.064099 \tValidation Loss: 0.171884\n",
            "Epoch: 9 \tTraining Loss: 0.052411 \tValidation Loss: 0.166110\n",
            "Epoch: 10 \tTraining Loss: 0.043140 \tValidation Loss: 0.171948\n",
            "Test Accuracy of the model: 94.5 %\n",
            "Done for AnB+ model retaining 2 layers\n",
            "Starting for AnB+ model retaining 3 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.318965 \tValidation Loss: 0.231427\n",
            "Epoch: 2 \tTraining Loss: 0.149066 \tValidation Loss: 0.159910\n",
            "Epoch: 3 \tTraining Loss: 0.108093 \tValidation Loss: 0.112912\n",
            "Epoch: 4 \tTraining Loss: 0.082480 \tValidation Loss: 0.118151\n",
            "Epoch: 5 \tTraining Loss: 0.073235 \tValidation Loss: 0.115011\n",
            "Epoch: 6 \tTraining Loss: 0.059267 \tValidation Loss: 0.143417\n",
            "Epoch: 7 \tTraining Loss: 0.048083 \tValidation Loss: 0.173901\n",
            "Epoch: 8 \tTraining Loss: 0.051643 \tValidation Loss: 0.126343\n",
            "Epoch: 9 \tTraining Loss: 0.035494 \tValidation Loss: 0.195770\n",
            "Epoch: 10 \tTraining Loss: 0.031177 \tValidation Loss: 0.164673\n",
            "Test Accuracy of the model: 95.66 %\n",
            "Done for AnB+ model retaining 3 layers\n",
            "Starting for AnB+ model retaining 4 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.257331 \tValidation Loss: 0.124893\n",
            "Epoch: 2 \tTraining Loss: 0.118726 \tValidation Loss: 0.103534\n",
            "Epoch: 3 \tTraining Loss: 0.085872 \tValidation Loss: 0.102928\n",
            "Epoch: 4 \tTraining Loss: 0.064825 \tValidation Loss: 0.094144\n",
            "Epoch: 5 \tTraining Loss: 0.054935 \tValidation Loss: 0.105071\n",
            "Epoch: 6 \tTraining Loss: 0.043471 \tValidation Loss: 0.122495\n",
            "Epoch: 7 \tTraining Loss: 0.038367 \tValidation Loss: 0.144411\n",
            "Epoch: 8 \tTraining Loss: 0.030553 \tValidation Loss: 0.099545\n",
            "Epoch: 9 \tTraining Loss: 0.029860 \tValidation Loss: 0.134186\n",
            "Epoch: 10 \tTraining Loss: 0.028146 \tValidation Loss: 0.317503\n",
            "Test Accuracy of the model: 93.36 %\n",
            "Done for AnB+ model retaining 4 layers\n",
            "Starting for AnB+ model retaining 5 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.187743 \tValidation Loss: 0.121853\n",
            "Epoch: 2 \tTraining Loss: 0.110415 \tValidation Loss: 0.107788\n",
            "Epoch: 3 \tTraining Loss: 0.076421 \tValidation Loss: 0.113530\n",
            "Epoch: 4 \tTraining Loss: 0.071073 \tValidation Loss: 0.096590\n",
            "Epoch: 5 \tTraining Loss: 0.050852 \tValidation Loss: 0.130476\n",
            "Epoch: 6 \tTraining Loss: 0.047339 \tValidation Loss: 0.116180\n",
            "Epoch: 7 \tTraining Loss: 0.042886 \tValidation Loss: 0.101026\n",
            "Epoch: 8 \tTraining Loss: 0.028816 \tValidation Loss: 0.112107\n",
            "Epoch: 9 \tTraining Loss: 0.028548 \tValidation Loss: 0.125190\n",
            "Epoch: 10 \tTraining Loss: 0.027232 \tValidation Loss: 0.112720\n",
            "Test Accuracy of the model: 95.96 %\n",
            "Done for AnB+ model retaining 5 layers\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}